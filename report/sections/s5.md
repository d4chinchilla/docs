5\. Final Product

First of all, to compare our specification and we have achieved, the
back-end successfully passed all the test by using the test data and it
shown it works for multiple angle with frequency up to 2000Hz. And the
back-end we specify that it needs to be calculated the angle with the
tolerance $\pm 9{^\circ}$. But it can produce the accuracy of
$0.01{^\circ}$ for a single sine wave. Also, the microphone can receive
the spoken voice and the pre-amp can output the voltage between 0 to
3.3V from the spoken voice. Moreover, the ADC to MCU communication can
work and sampling the frequency larger than 50kHz. Furthermore, we
specify that the Buffer communicates with Back-end at over 120kB/s.
However, it only able to communicate at 21.5kB/s. As well as this, the
WebUI is able to display the amplitude and angle of the incoming sound.
In addition, the device is fully constructed and we are able to put all
the components into the case which is made by a 3D-printer. In terms of
the LED ring, we can use it to represent the signal direction, the
frequency and the amplitude by using test data.

In terms of which we cannot achieved, is the WebUI cannot update at a
rate greater than 60fps. And the final device cannot reject artificial
ambient noise and therefore it cannot indicate the correct direction of
the signal in a noisy room.

![](media/image1.png){width="3.1595308398950133in"
height="2.5430555555555556in"}

Figure 1: photo of the final product with LED light

Next, for our final product, theoretically once an object emitted a
sound. The four microphones inside the device will amplify the sound
have been received and the ADCs which connected to each of the
microphones will convert the sound into a set of real values within a
range from 0 to 255. Then it will pass to a microcontroller and it
controls how the data to pass to the Raspberry Pi. Once the Raspberry Pi
received the sets of the real values which come from the
microcontroller, it will compute the program compiled in it. In
addition, it finds the direction of the sound by using cross-correlation
and the delay between 2 signals in order to calculate the angle of the
sound that it comes from. Also, the frequency of the sound is calculated
by using the Fourier Transform. Finally, the device will be able to show
the direction of the sound by turn on the LED light and the frequency of
the sound which is represented by the color of the LED.

Finally, for the further extensions of our device, we would like to add
filters to filter out the frequency which is higher than 12kHz which
enable the device not sampling the signal that we are not in use. Also,
we want to use the frequency to differentiating different sounds from
the microphones and improve the speed and accuracy of LED output.
Furthermore, we want the device able to sense the position of sounds in
absolute space, either distance or magnitude of the vertical angle.
